# ğŸŒ Solar Generation Forecasting with Transfer Learning  


## ğŸ” Introduction
The **global energy demand** is steadily increasing, leading to an urgent need for **renewable energy** adoption. Solar energy, though abundant, is highly dependent on **weather conditions** and remains **difficult to predict**. 

To address this challenge, this thesis explores the use of **deep learning models trained on large datasets** to **transfer knowledge** and improve solar energy predictions, even in **regions with limited data**.

---

## ğŸ› ï¸ Project Description
The main objective of this project is:
- **Development of pretrained Convolutional Neural Networks (CNNs)**
- **Fine-tuning models for time-series forecasting**
- **Comparison of deep learning models with statistical baselines**
- **Performance evaluation based on RMSE & MAE metrics**

The project is structured as follows:
1. **Data preprocessing**: Cleaning, normalizing, and structuring time-series energy and weather data.
2. **Model construction**: Designing **deep learning architectures** using **CNNs**.
3. **Transfer learning**: Training models on **large-scale datasets** and testing on **unseen data**.
4. **Performance evaluation**: Comparing **pretrained models** with statistical baselines.

---

## ğŸ“Š Dataset & Preprocessing
The dataset consists of two main sources:
1. **Weather Data**: Hourly temperature and solar radiation measurements from **2015-2019**.
2. **Solar Generation Data**: Hourly solar energy generation data from various **European countries**.

### ğŸ—ï¸ Preprocessing Steps:
âœ”ï¸ Handling **missing values** using interpolation and statistical techniques.  
âœ”ï¸ **Feature selection** & normalization of numerical values.  
âœ”ï¸ Application of **windowing methods** for time-series forecasting.  
âœ”ï¸ **Country selection** based on data quality and diversity.

---

## âš™ï¸ Methodology
The following machine learning models were implemented:

### **ğŸ”¹ Pretrained Deep Learning Models**
- **Three CNN architectures** trained on multiple European countries.
- Hyperparameter optimization using **Optuna framework**.
- **Dropout & BatchNormalization** layers for better generalization.
- Fine-tuning techniques to **improve learning rate & training efficiency**.

### **ğŸ”¹ Baseline Models**
- **Exponential Smoothing**
- **Theta Method**
- **NaÃ¯ve Mean & NaÃ¯ve Drift**
- **Simple CNN trained per country**

Pretrained models were tested on:
- **Countries in the training set**
- **Completely unknown countries**

**ğŸ“Œ Results showed that pretrained models significantly outperform traditional methods when trained on large-scale data.**

---

## ğŸ“ˆ Results & Findings
Key takeaways from the experiments:

âœ”ï¸ **Pretrained deep learning models** performed significantly better than models trained individually per country.  
âœ”ï¸ **Error reduction** of up to **300%** compared to statistical baselines.  
âœ”ï¸ **Deep architectures generalize better** and make **more accurate predictions** for **both known and unknown datasets**.  
âœ”ï¸ **Residual layers & Dropout** improved performance, but training time remained high.  
âœ”ï¸ **Predictions for unknown countries** were promising but require further optimization. 

## ğŸ”® Future Work
The next steps for further improvement: âœ”ï¸ Fine-tune models per country using freezing techniques.
âœ”ï¸ Incorporate weather forecasts as additional features.
âœ”ï¸ Optimize training time & improve model efficiency.
âœ”ï¸ Test additional deep learning architectures (LSTMs, Transformers, N-BEATS).
